{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "80691c20-24e4-4f09-b75f-c368b1221c2d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\adeun\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\adeun\\anaconda3\\lib\\site-packages (1.26.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\adeun\\anaconda3\\lib\\site-packages (1.5.1)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\adeun\\anaconda3\\lib\\site-packages (3.9.2)\n",
      "Requirement already satisfied: seaborn in c:\\users\\adeun\\anaconda3\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: imbalanced-learn in c:\\users\\adeun\\anaconda3\\lib\\site-packages (0.12.3)\n",
      "Requirement already satisfied: openpyxl in c:\\users\\adeun\\anaconda3\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\adeun\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\adeun\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\adeun\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\adeun\\anaconda3\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\adeun\\anaconda3\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\adeun\\anaconda3\\lib\\site-packages (from scikit-learn) (3.5.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\adeun\\anaconda3\\lib\\site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\adeun\\anaconda3\\lib\\site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\adeun\\anaconda3\\lib\\site-packages (from matplotlib) (4.51.0)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\adeun\\anaconda3\\lib\\site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\adeun\\anaconda3\\lib\\site-packages (from matplotlib) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\adeun\\anaconda3\\lib\\site-packages (from matplotlib) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\adeun\\anaconda3\\lib\\site-packages (from matplotlib) (3.1.2)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\adeun\\anaconda3\\lib\\site-packages (from openpyxl) (1.1.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\adeun\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas numpy scikit-learn matplotlib seaborn imbalanced-learn openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6efb829d-5808-4ee5-90db-e57c3a55c656",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imported Libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from collections import Counter # For checking class distribution\n",
    "\n",
    "# For imbalanced data handling\n",
    "from imblearn.over_sampling import SMOTE \n",
    "\n",
    "# Configure visualizations\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "72b8d4d5-5836-41bd-a181-bb2089f2f8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining file paths to the CSV files\n",
    "\n",
    "file_paths = [\n",
    "    'Monday-WorkingHours.pcap_ISCX.csv',\n",
    "    'Tuesday-WorkingHours.pcap_ISCX.csv',\n",
    "    'Wednesday-workingHours.pcap_ISCX.csv',\n",
    "    'Thursday-WorkingHours-Morning-WebAttacks.pcap_ISCX.csv',\n",
    "    'Thursday-WorkingHours-Afternoon-Infilteration.pcap_ISCX.csv',\n",
    "    'Friday-WorkingHours-Morning.pcap_ISCX.csv',\n",
    "    'Friday-WorkingHours-Afternoon-PortScan.pcap_ISCX.csv',\n",
    "    'Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35ffd24f-e4bd-4490-938d-c684db6f9457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded and merged successfully.\n",
      "Shape of the merged dataset: (2830743, 79)\n"
     ]
    }
   ],
   "source": [
    "# Loading and concatenating the CSV files\n",
    "\n",
    "try:\n",
    "    df_list = [pd.read_csv(file) for file in file_paths]\n",
    "    df = pd.concat(df_list, ignore_index=True)\n",
    "    print(\"Dataset loaded and merged successfully.\")\n",
    "    print(f\"Shape of the merged dataset: {df.shape}\")\n",
    "except FileNotFoundError:\n",
    "    print(\"ERROR: One or more CSV files not found. Please check your file_paths.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during loading/merging: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c6159922-bcd0-4b64-8c1e-81919a62eac1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- First 5 rows: ---\n",
      "    Destination Port   Flow Duration   Total Fwd Packets  \\\n",
      "0              49188               4                   2   \n",
      "1              49188               1                   2   \n",
      "2              49188               1                   2   \n",
      "3              49188               1                   2   \n",
      "4              49486               3                   2   \n",
      "\n",
      "    Total Backward Packets  Total Length of Fwd Packets  \\\n",
      "0                        0                           12   \n",
      "1                        0                           12   \n",
      "2                        0                           12   \n",
      "3                        0                           12   \n",
      "4                        0                           12   \n",
      "\n",
      "    Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
      "0                             0                       6   \n",
      "1                             0                       6   \n",
      "2                             0                       6   \n",
      "3                             0                       6   \n",
      "4                             0                       6   \n",
      "\n",
      "    Fwd Packet Length Min   Fwd Packet Length Mean   Fwd Packet Length Std  \\\n",
      "0                       6                      6.0                     0.0   \n",
      "1                       6                      6.0                     0.0   \n",
      "2                       6                      6.0                     0.0   \n",
      "3                       6                      6.0                     0.0   \n",
      "4                       6                      6.0                     0.0   \n",
      "\n",
      "   ...   min_seg_size_forward  Active Mean   Active Std   Active Max  \\\n",
      "0  ...                     20          0.0          0.0            0   \n",
      "1  ...                     20          0.0          0.0            0   \n",
      "2  ...                     20          0.0          0.0            0   \n",
      "3  ...                     20          0.0          0.0            0   \n",
      "4  ...                     20          0.0          0.0            0   \n",
      "\n",
      "    Active Min  Idle Mean   Idle Std   Idle Max   Idle Min   Label  \n",
      "0            0        0.0        0.0          0          0  BENIGN  \n",
      "1            0        0.0        0.0          0          0  BENIGN  \n",
      "2            0        0.0        0.0          0          0  BENIGN  \n",
      "3            0        0.0        0.0          0          0  BENIGN  \n",
      "4            0        0.0        0.0          0          0  BENIGN  \n",
      "\n",
      "[5 rows x 79 columns]\n",
      "\n",
      "--- DataFrame Info: ---\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2830743 entries, 0 to 2830742\n",
      "Data columns (total 79 columns):\n",
      " #   Column                        Dtype  \n",
      "---  ------                        -----  \n",
      " 0    Destination Port             int64  \n",
      " 1    Flow Duration                int64  \n",
      " 2    Total Fwd Packets            int64  \n",
      " 3    Total Backward Packets       int64  \n",
      " 4   Total Length of Fwd Packets   int64  \n",
      " 5    Total Length of Bwd Packets  int64  \n",
      " 6    Fwd Packet Length Max        int64  \n",
      " 7    Fwd Packet Length Min        int64  \n",
      " 8    Fwd Packet Length Mean       float64\n",
      " 9    Fwd Packet Length Std        float64\n",
      " 10  Bwd Packet Length Max         int64  \n",
      " 11   Bwd Packet Length Min        int64  \n",
      " 12   Bwd Packet Length Mean       float64\n",
      " 13   Bwd Packet Length Std        float64\n",
      " 14  Flow Bytes/s                  float64\n",
      " 15   Flow Packets/s               float64\n",
      " 16   Flow IAT Mean                float64\n",
      " 17   Flow IAT Std                 float64\n",
      " 18   Flow IAT Max                 int64  \n",
      " 19   Flow IAT Min                 int64  \n",
      " 20  Fwd IAT Total                 int64  \n",
      " 21   Fwd IAT Mean                 float64\n",
      " 22   Fwd IAT Std                  float64\n",
      " 23   Fwd IAT Max                  int64  \n",
      " 24   Fwd IAT Min                  int64  \n",
      " 25  Bwd IAT Total                 int64  \n",
      " 26   Bwd IAT Mean                 float64\n",
      " 27   Bwd IAT Std                  float64\n",
      " 28   Bwd IAT Max                  int64  \n",
      " 29   Bwd IAT Min                  int64  \n",
      " 30  Fwd PSH Flags                 int64  \n",
      " 31   Bwd PSH Flags                int64  \n",
      " 32   Fwd URG Flags                int64  \n",
      " 33   Bwd URG Flags                int64  \n",
      " 34   Fwd Header Length            int64  \n",
      " 35   Bwd Header Length            int64  \n",
      " 36  Fwd Packets/s                 float64\n",
      " 37   Bwd Packets/s                float64\n",
      " 38   Min Packet Length            int64  \n",
      " 39   Max Packet Length            int64  \n",
      " 40   Packet Length Mean           float64\n",
      " 41   Packet Length Std            float64\n",
      " 42   Packet Length Variance       float64\n",
      " 43  FIN Flag Count                int64  \n",
      " 44   SYN Flag Count               int64  \n",
      " 45   RST Flag Count               int64  \n",
      " 46   PSH Flag Count               int64  \n",
      " 47   ACK Flag Count               int64  \n",
      " 48   URG Flag Count               int64  \n",
      " 49   CWE Flag Count               int64  \n",
      " 50   ECE Flag Count               int64  \n",
      " 51   Down/Up Ratio                int64  \n",
      " 52   Average Packet Size          float64\n",
      " 53   Avg Fwd Segment Size         float64\n",
      " 54   Avg Bwd Segment Size         float64\n",
      " 55   Fwd Header Length.1          int64  \n",
      " 56  Fwd Avg Bytes/Bulk            int64  \n",
      " 57   Fwd Avg Packets/Bulk         int64  \n",
      " 58   Fwd Avg Bulk Rate            int64  \n",
      " 59   Bwd Avg Bytes/Bulk           int64  \n",
      " 60   Bwd Avg Packets/Bulk         int64  \n",
      " 61  Bwd Avg Bulk Rate             int64  \n",
      " 62  Subflow Fwd Packets           int64  \n",
      " 63   Subflow Fwd Bytes            int64  \n",
      " 64   Subflow Bwd Packets          int64  \n",
      " 65   Subflow Bwd Bytes            int64  \n",
      " 66  Init_Win_bytes_forward        int64  \n",
      " 67   Init_Win_bytes_backward      int64  \n",
      " 68   act_data_pkt_fwd             int64  \n",
      " 69   min_seg_size_forward         int64  \n",
      " 70  Active Mean                   float64\n",
      " 71   Active Std                   float64\n",
      " 72   Active Max                   int64  \n",
      " 73   Active Min                   int64  \n",
      " 74  Idle Mean                     float64\n",
      " 75   Idle Std                     float64\n",
      " 76   Idle Max                     int64  \n",
      " 77   Idle Min                     int64  \n",
      " 78   Label                        object \n",
      "dtypes: float64(24), int64(54), object(1)\n",
      "memory usage: 1.7+ GB\n",
      "\n",
      "--- Descriptive Statistics (Numerical Features): ---\n",
      "        Destination Port   Flow Duration   Total Fwd Packets  \\\n",
      "count       2.830743e+06    2.830743e+06        2.830743e+06   \n",
      "mean        8.071483e+03    1.478566e+07        9.361160e+00   \n",
      "std         1.828363e+04    3.365374e+07        7.496728e+02   \n",
      "min         0.000000e+00   -1.300000e+01        1.000000e+00   \n",
      "25%         5.300000e+01    1.550000e+02        2.000000e+00   \n",
      "50%         8.000000e+01    3.131600e+04        2.000000e+00   \n",
      "75%         4.430000e+02    3.204828e+06        5.000000e+00   \n",
      "max         6.553500e+04    1.200000e+08        2.197590e+05   \n",
      "\n",
      "        Total Backward Packets  Total Length of Fwd Packets  \\\n",
      "count             2.830743e+06                 2.830743e+06   \n",
      "mean              1.039377e+01                 5.493024e+02   \n",
      "std               9.973883e+02                 9.993589e+03   \n",
      "min               0.000000e+00                 0.000000e+00   \n",
      "25%               1.000000e+00                 1.200000e+01   \n",
      "50%               2.000000e+00                 6.200000e+01   \n",
      "75%               4.000000e+00                 1.870000e+02   \n",
      "max               2.919220e+05                 1.290000e+07   \n",
      "\n",
      "        Total Length of Bwd Packets   Fwd Packet Length Max  \\\n",
      "count                  2.830743e+06            2.830743e+06   \n",
      "mean                   1.616264e+04            2.075999e+02   \n",
      "std                    2.263088e+06            7.171848e+02   \n",
      "min                    0.000000e+00            0.000000e+00   \n",
      "25%                    0.000000e+00            6.000000e+00   \n",
      "50%                    1.230000e+02            3.700000e+01   \n",
      "75%                    4.820000e+02            8.100000e+01   \n",
      "max                    6.554530e+08            2.482000e+04   \n",
      "\n",
      "        Fwd Packet Length Min   Fwd Packet Length Mean  \\\n",
      "count            2.830743e+06             2.830743e+06   \n",
      "mean             1.871366e+01             5.820194e+01   \n",
      "std              6.033935e+01             1.860912e+02   \n",
      "min              0.000000e+00             0.000000e+00   \n",
      "25%              0.000000e+00             6.000000e+00   \n",
      "50%              2.000000e+00             3.400000e+01   \n",
      "75%              3.600000e+01             5.000000e+01   \n",
      "max              2.325000e+03             5.940857e+03   \n",
      "\n",
      "        Fwd Packet Length Std  ...   act_data_pkt_fwd   min_seg_size_forward  \\\n",
      "count            2.830743e+06  ...       2.830743e+06           2.830743e+06   \n",
      "mean             6.891013e+01  ...       5.418218e+00          -2.741688e+03   \n",
      "std              2.811871e+02  ...       6.364257e+02           1.084989e+06   \n",
      "min              0.000000e+00  ...       0.000000e+00          -5.368707e+08   \n",
      "25%              0.000000e+00  ...       0.000000e+00           2.000000e+01   \n",
      "50%              0.000000e+00  ...       1.000000e+00           2.400000e+01   \n",
      "75%              2.616295e+01  ...       2.000000e+00           3.200000e+01   \n",
      "max              7.125597e+03  ...       2.135570e+05           1.380000e+02   \n",
      "\n",
      "        Active Mean    Active Std    Active Max    Active Min     Idle Mean  \\\n",
      "count  2.830743e+06  2.830743e+06  2.830743e+06  2.830743e+06  2.830743e+06   \n",
      "mean   8.155132e+04  4.113412e+04  1.531825e+05  5.829582e+04  8.316037e+06   \n",
      "std    6.485999e+05  3.933815e+05  1.025825e+06  5.770923e+05  2.363008e+07   \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "25%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "50%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "75%    0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00  0.000000e+00   \n",
      "max    1.100000e+08  7.420000e+07  1.100000e+08  1.100000e+08  1.200000e+08   \n",
      "\n",
      "           Idle Std      Idle Max      Idle Min  \n",
      "count  2.830743e+06  2.830743e+06  2.830743e+06  \n",
      "mean   5.038439e+05  8.695752e+06  7.920031e+06  \n",
      "std    4.602984e+06  2.436689e+07  2.336342e+07  \n",
      "min    0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "25%    0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "50%    0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "75%    0.000000e+00  0.000000e+00  0.000000e+00  \n",
      "max    7.690000e+07  1.200000e+08  1.200000e+08  \n",
      "\n",
      "[8 rows x 78 columns]\n",
      "\n",
      "--- Value Counts for 'Label' column (Target Variable): ---\n",
      " Label\n",
      "BENIGN                        2273097\n",
      "DoS Hulk                       231073\n",
      "PortScan                       158930\n",
      "DDoS                           128027\n",
      "DoS GoldenEye                   10293\n",
      "FTP-Patator                      7938\n",
      "SSH-Patator                      5897\n",
      "DoS slowloris                    5796\n",
      "DoS Slowhttptest                 5499\n",
      "Bot                              1966\n",
      "Web Attack � Brute Force         1507\n",
      "Web Attack � XSS                  652\n",
      "Infiltration                       36\n",
      "Web Attack � Sql Injection         21\n",
      "Heartbleed                         11\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Basic DataFrame exploration\n",
    "if 'df' in locals(): # Check if df was loaded\n",
    "    print(\"--- First 5 rows: ---\")\n",
    "    print(df.head())\n",
    "    print(\"\\n--- DataFrame Info: ---\")\n",
    "    df.info() # Provides data types and non-null count\n",
    "    print(\"\\n--- Descriptive Statistics (Numerical Features): ---\")\n",
    "    print(df.describe())\n",
    "    print(\"\\n--- Value Counts for 'Label' column (Target Variable): ---\")\n",
    "    if ' Label' in df.columns:\n",
    "        print(df[' Label'].value_counts())\n",
    "    elif 'Label' in df.columns:\n",
    "        print(df['Label'].value_counts())\n",
    "    else:\n",
    "        print(\"Label column not found with common names (' Label' or 'Label'). Check column names.\")\n",
    "else:\n",
    "    print(\"DataFrame 'df' not found. Please ensure data loading was successful.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ceba1693-4547-4a59-80d8-bb6d79f2be9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names stripped.\n"
     ]
    }
   ],
   "source": [
    "# Cleaning Column Names\n",
    "if 'df' in locals():\n",
    "    original_columns = df.columns.tolist()\n",
    "    df.columns = df.columns.str.strip()\n",
    "    new_columns = df.columns.tolist()\n",
    "    if original_columns != new_columns:\n",
    "        print(\"Column names stripped.\")\n",
    "        # print(f\"Old columns: {original_columns}\")\n",
    "        # print(f\"New columns: {new_columns}\")\n",
    "    else:\n",
    "        print(\"Column names did not require stripping or were already clean.\")\n",
    "    \n",
    "    # Standardizing the target column name if needed\n",
    "    if 'Label' not in df.columns and ' Label' in df.columns:\n",
    "        df.rename(columns={' Label': 'Label'}, inplace=True)\n",
    "        print(\"Renamed ' Label' column to 'Label'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b67dc55b-179a-4062-ad55-d4a0b1e42f9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values before imputation: 5734\n",
      "Rows with NaN values dropped.\n",
      "Number of NaN values after imputation: 0\n",
      "Shape after dropping rows with NaN in 'Label': (2827876, 79)\n"
     ]
    }
   ],
   "source": [
    "# Handling Missing Values (NaNs) and Infinite Values\n",
    "if 'df' in locals():\n",
    "\n",
    "    df.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "    print(f\"Number of NaN values before imputation: {df.isnull().sum().sum()}\")\n",
    "\n",
    "    df.dropna(inplace=True)\n",
    "    print(\"Rows with NaN values dropped.\")\n",
    "\n",
    "    numerical_cols = df.select_dtypes(include=np.number).columns\n",
    "\n",
    "    if 'Label' in numerical_cols:\n",
    "        numerical_cols = numerical_cols.drop('Label') \n",
    "\n",
    "    imputer_median = SimpleImputer(strategy='median')\n",
    "    df[numerical_cols] = imputer_median.fit_transform(df[numerical_cols])\n",
    "    print(f\"Number of NaN values after imputation: {df.isnull().sum().sum()}\")\n",
    "    \n",
    "    if 'Label' in df.columns:\n",
    "        df.dropna(subset=['Label'], inplace=True)\n",
    "        print(f\"Shape after dropping rows with NaN in 'Label': {df.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bad226f1-84f7-4cb5-b64b-3c03d8e2870b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed 307078 duplicate rows.\n",
      "Shape after removing duplicates: (2520798, 79)\n"
     ]
    }
   ],
   "source": [
    "# Removing Duplicate Rows\n",
    "if 'df' in locals():\n",
    "    duplicates_before = df.duplicated().sum()\n",
    "    if duplicates_before > 0:\n",
    "        df.drop_duplicates(inplace=True)\n",
    "        print(f\"Removed {duplicates_before} duplicate rows.\")\n",
    "        print(f\"Shape after removing duplicates: {df.shape}\")\n",
    "    else:\n",
    "        print(\"No duplicate rows found.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c7594e1e-5824-40b1-a9ec-46bc05890861",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X (features): (2520798, 78)\n",
      "Shape of y (target): (2520798,)\n",
      "\n",
      "Features for the model (X columns):\n",
      "['Destination Port', 'Flow Duration', 'Total Fwd Packets', 'Total Backward Packets', 'Total Length of Fwd Packets', 'Total Length of Bwd Packets', 'Fwd Packet Length Max', 'Fwd Packet Length Min', 'Fwd Packet Length Mean', 'Fwd Packet Length Std', 'Bwd Packet Length Max', 'Bwd Packet Length Min', 'Bwd Packet Length Mean', 'Bwd Packet Length Std', 'Flow Bytes/s', 'Flow Packets/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Flow IAT Min', 'Fwd IAT Total', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Fwd IAT Min', 'Bwd IAT Total', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Bwd IAT Min', 'Fwd PSH Flags', 'Bwd PSH Flags', 'Fwd URG Flags', 'Bwd URG Flags', 'Fwd Header Length', 'Bwd Header Length', 'Fwd Packets/s', 'Bwd Packets/s', 'Min Packet Length', 'Max Packet Length', 'Packet Length Mean', 'Packet Length Std', 'Packet Length Variance', 'FIN Flag Count', 'SYN Flag Count', 'RST Flag Count', 'PSH Flag Count', 'ACK Flag Count', 'URG Flag Count', 'CWE Flag Count', 'ECE Flag Count', 'Down/Up Ratio', 'Average Packet Size', 'Avg Fwd Segment Size', 'Avg Bwd Segment Size', 'Fwd Header Length.1', 'Fwd Avg Bytes/Bulk', 'Fwd Avg Packets/Bulk', 'Fwd Avg Bulk Rate', 'Bwd Avg Bytes/Bulk', 'Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets', 'Subflow Fwd Bytes', 'Subflow Bwd Packets', 'Subflow Bwd Bytes', 'Init_Win_bytes_forward', 'Init_Win_bytes_backward', 'act_data_pkt_fwd', 'min_seg_size_forward', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']\n"
     ]
    }
   ],
   "source": [
    "# Feature Selection\n",
    "if 'df' in locals() and 'Label' in df.columns:\n",
    "\n",
    "    features_to_drop_manual = ['Flow ID', 'Source IP', 'Destination IP', 'Timestamp', 'Source Port'] \n",
    "  \n",
    "    X = df.drop('Label', axis=1)\n",
    "    y_categorical = df['Label'] # Keep the categorical labels for now for EDA, encode later for model\n",
    "\n",
    "    print(f\"Shape of X (features): {X.shape}\")\n",
    "    print(f\"Shape of y (target): {y_categorical.shape}\")\n",
    "    print(\"\\nFeatures for the model (X columns):\")\n",
    "    print(X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "5db7ad6c-4908-4e2d-9b7d-4afb47f6ed8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Target variable 'Label' encoded.\n",
      "Mapping of encoded labels to original categories:\n",
      "0: BENIGN\n",
      "1: Bot\n",
      "2: DDoS\n",
      "3: DoS GoldenEye\n",
      "4: DoS Hulk\n",
      "5: DoS Slowhttptest\n",
      "6: DoS slowloris\n",
      "7: FTP-Patator\n",
      "8: Heartbleed\n",
      "9: Infiltration\n",
      "10: PortScan\n",
      "11: SSH-Patator\n",
      "12: Web Attack � Brute Force\n",
      "13: Web Attack � Sql Injection\n",
      "14: Web Attack � XSS\n",
      "\n",
      "Class distribution in y (encoded):\n",
      "Counter({0: 2095057, 4: 172846, 2: 128014, 10: 90694, 3: 10286, 7: 5931, 6: 5385, 5: 5228, 11: 3219, 1: 1948, 12: 1470, 14: 652, 9: 36, 13: 21, 8: 11})\n",
      "Features scaled.\n",
      "--- Scaled Features (first 5 rows): ---\n",
      "   Destination Port  Flow Duration  Total Fwd Packets  Total Backward Packets  \\\n",
      "0          0.750561   1.416667e-07           0.000005                0.000000   \n",
      "1          0.750561   1.166667e-07           0.000005                0.000000   \n",
      "4          0.755108   1.333333e-07           0.000005                0.000000   \n",
      "5          0.755108   1.166667e-07           0.000005                0.000000   \n",
      "8          0.001343   5.183333e-06           0.000027                0.000014   \n",
      "\n",
      "   Total Length of Fwd Packets  Total Length of Bwd Packets  \\\n",
      "0                 9.302326e-07                 0.000000e+00   \n",
      "1                 9.302326e-07                 0.000000e+00   \n",
      "4                 9.302326e-07                 0.000000e+00   \n",
      "5                 9.302326e-07                 0.000000e+00   \n",
      "8                 3.751938e-05                 6.316242e-07   \n",
      "\n",
      "   Fwd Packet Length Max  Fwd Packet Length Min  Fwd Packet Length Mean  \\\n",
      "0               0.000242               0.002581                0.001010   \n",
      "1               0.000242               0.002581                0.001010   \n",
      "4               0.000242               0.002581                0.001010   \n",
      "5               0.000242               0.002581                0.001010   \n",
      "8               0.009388               0.000000                0.011639   \n",
      "\n",
      "   Fwd Packet Length Std  ...  act_data_pkt_fwd  min_seg_size_forward  \\\n",
      "0               0.000000  ...          0.000005                   1.0   \n",
      "1               0.000000  ...          0.000005                   1.0   \n",
      "4               0.000000  ...          0.000005                   1.0   \n",
      "5               0.000000  ...          0.000005                   1.0   \n",
      "8               0.015713  ...          0.000023                   1.0   \n",
      "\n",
      "   Active Mean  Active Std  Active Max  Active Min  Idle Mean  Idle Std  \\\n",
      "0          0.0         0.0         0.0         0.0        0.0       0.0   \n",
      "1          0.0         0.0         0.0         0.0        0.0       0.0   \n",
      "4          0.0         0.0         0.0         0.0        0.0       0.0   \n",
      "5          0.0         0.0         0.0         0.0        0.0       0.0   \n",
      "8          0.0         0.0         0.0         0.0        0.0       0.0   \n",
      "\n",
      "   Idle Max  Idle Min  \n",
      "0       0.0       0.0  \n",
      "1       0.0       0.0  \n",
      "4       0.0       0.0  \n",
      "5       0.0       0.0  \n",
      "8       0.0       0.0  \n",
      "\n",
      "[5 rows x 78 columns]\n"
     ]
    }
   ],
   "source": [
    "# Encoding Categorical Target Variable\n",
    "if 'y_categorical' in locals():\n",
    "    label_encoder = LabelEncoder()\n",
    "    y = label_encoder.fit_transform(y_categorical) \n",
    "    print(\"Target variable 'Label' encoded.\")\n",
    "    print(\"Mapping of encoded labels to original categories:\")\n",
    "    for i, class_name in enumerate(label_encoder.classes_):\n",
    "        print(f\"{i}: {class_name}\")\n",
    "    print(\"\\nClass distribution in y (encoded):\")\n",
    "    print(Counter(y))\n",
    "\n",
    "# Normalization with MinMaxScaler\n",
    "\n",
    "if 'X' in locals():\n",
    "    # Ensure X contains only numerical data before scaling\n",
    "    if not X.select_dtypes(include=np.number).shape[1] == X.shape[1]:\n",
    "        print(\"Warning: Non-numeric columns detected in X. Scaling will only apply to numeric ones.\")\n",
    "\n",
    "        X_numeric = X.select_dtypes(include=np.number)\n",
    "    else:\n",
    "        X_numeric = X\n",
    "\n",
    "    scaler = MinMaxScaler() \n",
    "    \n",
    "    X_scaled = scaler.fit_transform(X_numeric)\n",
    "\n",
    "    X_scaled_df = pd.DataFrame(X_scaled, columns=X_numeric.columns, index=X_numeric.index)\n",
    "    \n",
    "    print(\"Features scaled.\")\n",
    "    print(\"--- Scaled Features (first 5 rows): ---\")\n",
    "    print(X_scaled_df.head())\n",
    "    \n",
    "    X = X_scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1bf46143-f3d1-4373-a95a-127f71c00923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data split into training, validation, and testing sets.\n",
      "X_train shape: (1512478, 78), y_train shape: (1512478,)\n",
      "X_val shape: (504160, 78), y_val shape: (504160,)\n",
      "X_test shape: (504160, 78), y_test shape: (504160,)\n",
      "\n",
      "Training set label distribution:\n",
      "Counter({0: 1257033, 4: 103707, 2: 76808, 10: 54416, 3: 6172, 7: 3559, 6: 3231, 5: 3137, 11: 1931, 1: 1169, 12: 882, 14: 391, 9: 22, 13: 13, 8: 7})\n",
      "\n",
      "Validation set label distribution:\n",
      "Counter({0: 419012, 4: 34570, 2: 25603, 10: 18139, 3: 2057, 7: 1186, 6: 1077, 5: 1045, 11: 644, 1: 389, 12: 294, 14: 131, 9: 7, 13: 4, 8: 2})\n",
      "\n",
      "Test set label distribution:\n",
      "Counter({0: 419012, 4: 34569, 2: 25603, 10: 18139, 3: 2057, 7: 1186, 6: 1077, 5: 1046, 11: 644, 1: 390, 12: 294, 14: 130, 9: 7, 13: 4, 8: 2})\n",
      "\n",
      "Approximate proportions:\n",
      "Train: 0.60, Validation: 0.20, Test: 0.20\n"
     ]
    }
   ],
   "source": [
    "# Spliting Data into Training, Validation and Testing sets\n",
    "\n",
    "if 'X' in locals() and 'y' in locals():\n",
    "\n",
    "    TRAIN_RATIO = 0.60\n",
    "    VALIDATION_RATIO = 0.20\n",
    "    TEST_RATIO = 0.20\n",
    "\n",
    "    RANDOM_STATE = 42 \n",
    "\n",
    "    # First split\n",
    "    \n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(\n",
    "        X, y, \n",
    "        test_size=(VALIDATION_RATIO + TEST_RATIO), \n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=y \n",
    "    )\n",
    "\n",
    "    # Second split\n",
    "    \n",
    "    relative_test_ratio = TEST_RATIO / (VALIDATION_RATIO + TEST_RATIO)\n",
    "    \n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_temp, y_temp,\n",
    "        test_size=relative_test_ratio,\n",
    "        random_state=RANDOM_STATE,\n",
    "        stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    print(\"Data split into training, validation, and testing sets.\")\n",
    "    print(f\"X_train shape: {X_train.shape}, y_train shape: {y_train.shape}\")\n",
    "    print(f\"X_val shape: {X_val.shape}, y_val shape: {y_val.shape}\")\n",
    "    print(f\"X_test shape: {X_test.shape}, y_test shape: {y_test.shape}\")\n",
    "    \n",
    "    print(\"\\nTraining set label distribution:\")\n",
    "    print(Counter(y_train))\n",
    "    print(\"\\nValidation set label distribution:\")\n",
    "    print(Counter(y_val))\n",
    "    print(\"\\nTest set label distribution:\")\n",
    "    print(Counter(y_test))\n",
    "\n",
    "    # Verify the overall proportions (approximate due to discrete sample counts)\n",
    "    print(f\"\\nApproximate proportions:\")\n",
    "    print(f\"Train: {len(X_train)/len(X):.2f}, Validation: {len(X_val)/len(X):.2f}, Test: {len(X_test)/len(X):.2f}\")\n",
    "\n",
    "else:\n",
    "    print(\"X and/or y variables not found. Please ensure previous cells ran correctly and X (features) and y (encoded target) are defined.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "ffeeed68-b9d5-42ff-8a55-5dadd27f309c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original training set label distribution: Counter({0: 1257033, 4: 103707, 2: 76808, 10: 54416, 3: 6172, 7: 3559, 6: 3231, 5: 3137, 11: 1931, 1: 1169, 12: 882, 14: 391, 9: 22, 13: 13, 8: 7})\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Adeun\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\Adeun\\anaconda3\\Lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "               ^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Adeun\\anaconda3\\Lib\\subprocess.py\", line 548, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "         ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"C:\\Users\\Adeun\\anaconda3\\Lib\\subprocess.py\", line 1026, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\Adeun\\anaconda3\\Lib\\subprocess.py\", line 1538, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE applied to the training data.\n",
      "Resampled training set label distribution: Counter({0: 1257033, 4: 1257033, 2: 1257033, 10: 1257033, 7: 1257033, 6: 1257033, 3: 1257033, 5: 1257033, 11: 1257033, 12: 1257033, 1: 1257033, 14: 1257033, 9: 1257033, 13: 1257033, 8: 1257033})\n"
     ]
    }
   ],
   "source": [
    "# Handling Imbalanced Data on the Training Set using SMOTE\n",
    "\n",
    "if 'X_train' in locals():\n",
    "    print(\"Original training set label distribution:\", Counter(y_train))\n",
    "    \n",
    "    if not X_train.select_dtypes(include=np.number).shape[1] == X_train.shape[1]:\n",
    "        print(\"Error: SMOTE requires all features in X_train to be numeric.\")\n",
    "    else:\n",
    "        smote = SMOTE(random_state=42) # random_state from proposal\n",
    "        try:\n",
    "            X_train_resampled, y_train_resampled = smote.fit_resample(X_train, y_train)\n",
    "            print(\"SMOTE applied to the training data.\")\n",
    "            print(\"Resampled training set label distribution:\", Counter(y_train_resampled))\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error during SMOTE: {e}. Check data types and values in X_train.\")\n",
    "            print(\"Ensure no NaN/Inf values remain and all data is numeric.\")\n",
    "    \n",
    "            X_train_resampled = X_train \n",
    "            y_train_resampled = y_train\n",
    "\n",
    "else:\n",
    "    print(\"X_train not defined. Ensure previous cells ran correctly.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9403a583-0770-443e-8839-cf0bd5a4957d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed training, validation, and test data saved.\n",
      "Label encoder and scaler saved.\n"
     ]
    }
   ],
   "source": [
    "# Saving the preprocessed data\n",
    "\n",
    "if ('X_train_resampled' in locals() and \\\n",
    "    'y_train_resampled' in locals() and \\\n",
    "    'X_val' in locals() and \\\n",
    "    'y_val' in locals() and \\\n",
    "    'X_test' in locals() and \\\n",
    "    'y_test' in locals() and \\\n",
    "    'X' in locals() and hasattr(X, 'columns') and \\\n",
    "    'label_encoder' in locals() and \\\n",
    "    'scaler' in locals()):\n",
    "    \n",
    "    # Training Data\n",
    "    X_train_save = pd.DataFrame(X_train_resampled, columns=X.columns)\n",
    "    y_train_save = pd.DataFrame(y_train_resampled, columns=['Label']) \n",
    "\n",
    "    # Validation Data\n",
    "    X_val_save = pd.DataFrame(X_val, columns=X.columns)\n",
    "    y_val_save = pd.DataFrame(y_val, columns=['Label'])\n",
    "\n",
    "    # Test Data\n",
    "    X_test_save = pd.DataFrame(X_test, columns=X.columns)\n",
    "    y_test_save = pd.DataFrame(y_test, columns=['Label'])\n",
    "\n",
    "    # Saving to CSV files\n",
    "    try:\n",
    "        X_train_save.to_csv('X_train_preprocessed.csv', index=False)\n",
    "        y_train_save.to_csv('y_train_preprocessed.csv', index=False)\n",
    "        \n",
    "        X_val_save.to_csv('X_val_preprocessed.csv', index=False)\n",
    "        y_val_save.to_csv('y_val_preprocessed.csv', index=False)\n",
    "        \n",
    "        X_test_save.to_csv('X_test_preprocessed.csv', index=False)\n",
    "        y_test_save.to_csv('y_test_preprocessed.csv', index=False)\n",
    "        \n",
    "        print(f\"Preprocessed training, validation, and test data saved.\")\n",
    "\n",
    "        # Saving the label encoder and scaler\n",
    "        import joblib\n",
    "        joblib.dump(label_encoder,'cicids2017_label_encoder.joblib')\n",
    "        joblib.dump(scaler,'cicids2017_scaler.joblib')\n",
    "        print(f\"Label encoder and scaler saved.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error during saving: {e}\")\n",
    "\n",
    "else:\n",
    "    print(\"One or more required data components (e.g., X_train_resampled, X_val, y_val, X_test, X with columns, label_encoder, scaler) not found for saving.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee686ce-f31e-4a22-b9cd-967a25e6824f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
